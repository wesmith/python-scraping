{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq  # WS mod\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url):  # WS for macosx?\n",
    "    \"\"\"\n",
    "    Utilty function used to get a Beautiful Soup object from a given URL\n",
    "    \"\"\"\n",
    "    session = rq.Session()\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'}\n",
    "    try:\n",
    "        req = session.get(url, headers=headers)\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "    bs = BeautifulSoup(req.text, 'html.parser')\n",
    "    return bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with different website layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url   = url\n",
    "        self.title = title\n",
    "        self.body  = body\n",
    "\n",
    "def getPage(url):\n",
    "    req = rq.get(url)\n",
    "    return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "def scrapeNYTimes(url):\n",
    "    bs    = getPage(url)\n",
    "    title = bs.find('h1').text\n",
    "    lines = bs.select('div.StoryBodyCompanionColumn div p')\n",
    "    body  = '\\n'.join([line.text for line in lines])\n",
    "    return Content(url, title, body)\n",
    "\n",
    "def scrapeBrookings(url):\n",
    "    bs    = getPage(url)\n",
    "    title = bs.find('h1').text\n",
    "    body  = bs.find('div', {'class', 'post-body'}).text\n",
    "    return Content(url, title, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Delivering inclusive urban access: 3 uncomfortable truths\n",
      "URL: https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/\n",
      "\n",
      "\n",
      "The past few decades have been filled with a deep optimism about the role of cities and suburbs across the world. These engines of economic growth host a majority of world population, are major drivers of economic innovation, and have created pathways to opportunities for untold amounts of people.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jeffrey Gutman\n",
      "\n",
      "\t\t\t\t\tFormer Nonresident Fellow, Global Economy and Development\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Adie Tomer\n",
      "\n",
      "\t\t\t\t\tSenior Fellow - Brookings Metro \n",
      "\n",
      " Twitter\n",
      "AdieTomer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But all is not well within our so-called Urban Century. Rapid urbanization, rising gentrification, concentrated poverty, and shortages of basic infrastructure have combined to create spatial inequity in cities and suburbs across the globe. The challenges of housing, moving, and employing so many people have led to longer travel times, rising housing costs, and unsustainable public spending. Moreover, policymakers are questioning traditional policies and approaches.\n",
      "The past couple years, we’ve led a project at Brookings—Moving to Access—that responds to these spatial challenges by promoting the idea of connecting people to opportunities as a new foundational principle for 21st century urban development. This principle of accessibility is meant to be a corollary to the natural questions we ask ourselves everyday about the communities where we live: Is this the best location to access employment? Are there nearby schools and health services? Is there a market in the neighborhood? How can I get from here to there? Such choices are valid for those with sufficient income. But what about those with more limited resources and thus choices in terms of affordable housing and affordable transport?\n",
      "While economists, planners, and engineers have promoted accessibility for decades, the concept is more often found in textbooks than formal urban policies. In the first stage of this project, we worked with a team of experts to determine what has stalled practical implementation of appropriate policies and practices? “Delivering Inclusive Access,” a report of this initial work, offers a synthesis of what we found and where we believe researchers, policymakers, and practitioners can take this work next. The paper found three central challenges.\n",
      "The fallacy of the single indicator\n",
      "The current transport regime’s approach to measurement is one of outward elegance: The dominant pursuit is speed, and the primary way to measure it is congestion (or what slows us down). Many have come to label this approach a pursuit of “mobility.” It is seen through different, but often singular, measures of how congestion affects a specific roadway. Such singular measures are easily interpreted by policymakers and civil society and can be translated directly into economic analysis of related investments through timesavings. They also conveniently serve such purposes as the internationally agreed-upon Sustainable Development Goals. Yet they actually don’t answer the fundamental question of who can reach where, in how much time, and at what cost.\n",
      "\n",
      "\n",
      "Related Content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Report\n",
      "Delivering inclusive access\n",
      "\n",
      "Jeffrey Gutman, Adie Tomer, Joseph W. Kane, Nirav Patel, and Ranjitha Shivaram\n",
      "August 2017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Report\n",
      "Measuring performance: Accessibility metrics in metropolitan regions around the world\n",
      "\n",
      "Geneviève Boisjoly and Ahmed El-Geneidy\n",
      "August 2017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Report\n",
      "Is better access key to inclusive cities?\n",
      "\n",
      "Jeffrey Gutman and Nirav Patel\n",
      "Wednesday, October 5, 2016\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accessibility measures can answer those questions, but not through any one measure. First, the variable social, economic, and political contexts related to access mean searching for a single magical indicator is counterintuitive. For example, a wealthy, automobile-centric region like Dallas, Texas, may have very different measurable goals than a denser, poorer region like Dar es Salaam, Tanzania. Second, academic literature is now rife with such complex measures that it could be difficult to communicate their methodology and results with practitioners. The development of a suite of indicators could offer a menu for policymakers and practitioners to judge accessibility based on local objectives, local conditions, and local capacity.\n",
      "The danger of excessive localization\n",
      "Decentralization and empowering local communities is fast becoming a mantra of governance experts across the world, from development practitioners at institutions like the World Bank to city-focused theorists. And for good reason: delegating policy design and fiscal authority directly to the local level helps ensure policies and practices respond to local needs and desires. Yet as urban areas spillover into contiguous and often numerous municipalities, local independence can introduce certain challenges, especially relating to social and environmental externalities. When it comes to transportation and land development, interests of one municipality are often different from its neighbors. And these divergent development goals can exacerbate accessibility challenges within growing regions, spreading people, housing jobs, and other activities further from one another.\n",
      "Addressing spatial inequities in land use and real estate markets require a broader approach to horizontal governance. While there are examples of metropolitan transport authorities, there is less willingness to consider metropolitan or horizontal governance of land use and fiscal policies. For example, should housing be coordinated across an entire region?\n",
      "Countries with a more centralized top down approach to governance, such as France and Germany, have greater ability to formulate metropolitan governance than more decentralized countries such as the U.S. This is not to say there is a one-size-fits-all approach, but there is an opportunity to test different solutions within different governance contexts, comparing how effective each model is to promote spatial inclusivity.\n",
      "The finance community is missing in action\n",
      "Financing is a central topic in infrastructure circles. As maintenance bills from the automobile era come due, populations continue to grow, and fiscal budgets are tight, how can urban areas afford to build enough infrastructure to support future economic growth? In response, new approaches are evolving in fiscal instruments, such as value capture and private-public partnerships. Missing in these discussions, however, are the implications for inclusive access.\n",
      "We conducted a multi-decade review of past academic literature on access and found that there is no clear substantive discussion of accessibility from a fiscal perspective. While urban transport and land use professionals clearly recognize their interrelationship in achieving inclusive accessibility, at least in theory, the fiscal and finance professionals generally ignore the implications of their instruments with regard to inclusivity. The multilateral development banks and their economic evaluations have ignored the distributive impacts until very recently. And the efforts of some countries to incorporate measures through multi-criteria analysis have had limited impact.\n",
      "This gap must be resolved in any effort toward inclusive urban development. There is little doubt that fiscal approaches must carefully assess who ultimately pays and that alternative finance instruments should be adapted to foster access for all.\n",
      "Going forward\n",
      "Our research confirms that there are enormous opportunities to advance accessibility theory into practice. At this point, what is desperately needed is to launch a range of case studies that deal with these issues and challenges under different geographic, governance, and economic contexts. The good news is that many initiatives are already underway, and more robust communication channels and technology can support such efforts. In Chicago, researchers created an online platform to visually explore accessibility by location. In Bogota, researchers evaluated how affordability is a key principle of access. And in Cairo and Kigali, researchers used open tools to achieve new insights for accessibility. Sharing the results of these case studies could lead to a new level of cross-disciplinary approaches to improve accessibility and lessen the effects of spatial inequity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.brookings.edu/blog/future-development/2018/01/26/delivering-inclusive-urban-access-3-uncomfortable-truths/'\n",
    "content = scrapeBrookings(url)\n",
    "print('Title: {}'.format(content.title))\n",
    "print('URL: {}\\n'.format(content.url))\n",
    "print(content.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.nytimes.com/2018/01/25/opinion/sunday/silicon-valley-immortality.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mscrapeNYTimes\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(content\u001b[38;5;241m.\u001b[39mtitle))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(content\u001b[38;5;241m.\u001b[39murl))\n",
      "Cell \u001b[0;32mIn [4], line 13\u001b[0m, in \u001b[0;36mscrapeNYTimes\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrapeNYTimes\u001b[39m(url):\n\u001b[1;32m     12\u001b[0m     bs    \u001b[38;5;241m=\u001b[39m getPage(url)\n\u001b[0;32m---> 13\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m     14\u001b[0m     lines \u001b[38;5;241m=\u001b[39m bs\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.StoryBodyCompanionColumn div p\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     body  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([line\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# WS this is behind a paywall\n",
    "url = 'https://www.nytimes.com/2018/01/25/opinion/sunday/silicon-valley-immortality.html'\n",
    "content = scrapeNYTimes(url)\n",
    "print('Title: {}'.format(content.title))\n",
    "print('URL: {}\\n'.format(content.url))\n",
    "print(content.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"\n",
    "    Common base class for all articles/pages\n",
    "    \"\"\"\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url   = url\n",
    "        self.title = title\n",
    "        self.body  = body\n",
    "\n",
    "    def print(self):\n",
    "        \"\"\"\n",
    "        Flexible printing function controls output\n",
    "        \"\"\"\n",
    "        print('URL: {}'.format(self.url))\n",
    "        print('TITLE: {}'.format(self.title))\n",
    "        print('BODY:\\n{}'.format(self.body))\n",
    "\n",
    "class Website:\n",
    "    \"\"\" \n",
    "    Contains information about website structure\n",
    "    \"\"\"\n",
    "    def __init__(self, name, url, titleTag, bodyTag):\n",
    "        self.name     = name\n",
    "        self.url      = url\n",
    "        self.titleTag = titleTag\n",
    "        self.bodyTag  = bodyTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "\n",
    "    def getPage(self, url):\n",
    "        try:\n",
    "            req = rq.get(url)\n",
    "        except rq.exceptions.RequestException:\n",
    "            return None\n",
    "        return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "    def safeGet(self, pageObj, selector):\n",
    "        \"\"\"\n",
    "        Utilty function used to get a content string from a Beautiful Soup\n",
    "        object and a selector. Returns an empty string if no object\n",
    "        is found for the given selector\n",
    "        \"\"\"\n",
    "        selectedElems = pageObj.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "\n",
    "    def parse(self, site, url):\n",
    "        \"\"\"\n",
    "        Extract content from a given page URL\n",
    "        \"\"\"\n",
    "        bs = self.getPage(url)\n",
    "        if bs is not None:\n",
    "            title = self.safeGet(bs, site.titleTag)\n",
    "            body = self.safeGet(bs, site.bodyTag)\n",
    "            if title != '' and body != '':\n",
    "                content = Content(url, title, body)\n",
    "                content.print()\n",
    "            else:\n",
    "                print('title and body not found')  # WS\n",
    "        else:\n",
    "            print('url not found')  # WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()\n",
    "\n",
    "siteData = [\n",
    "    ['O\\'Reilly Media', 'http://oreilly.com', 'h1', 'section#product-description'],\n",
    "    ['Reuters', 'http://reuters.com', 'h1', 'div.StandardArticleBody_body_1gnLA'],\n",
    "    ['Brookings', 'http://www.brookings.edu', 'h1', 'div.post-body'],\n",
    "    ['New York Times', 'http://nytimes.com', 'h1', 'div.StoryBodyCompanionColumn div p']\n",
    "]\n",
    "websites = []\n",
    "for row in siteData:\n",
    "    #websites.append(Website(row[0], row[1], row[2], row[3]))\n",
    "    websites.append(Website(*row))  # WS list expansion: this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title and body not found\n"
     ]
    }
   ],
   "source": [
    "crawler.parse(websites[0], 'http://shop.oreilly.com/product/0636920028154.do')  # this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title and body not found\n"
     ]
    }
   ],
   "source": [
    "crawler.parse(\n",
    "    websites[1], 'http://www.reuters.com/article/us-usa-epa-pruitt-idUSKBN19W2D0')  # this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.brookings.edu/blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/\n",
      "TITLE: Idea to Retire: Old methods of policy education\n",
      "Idea to Retire: Old methods of policy education\n",
      "BODY:\n",
      "\n",
      "Public policy and public affairs schools aim to train competent creators and implementers of government policy. While drawing on the principles that gird our economic and political systems to provide a well-rounded education, like law schools and business schools, policy schools provide professional training. They are quite distinct from graduate programs in political science or economics which aim to train the next generation of academics. As professional training programs, they add value by imparting both the skills which are relevant to current employers, and skills which we know will be relevant as organizations and societies evolve. \n",
      "The relevance of the skills that policy programs impart to address problems of today and tomorrow bears further discussion. We are living through an era in which societies are increasingly interconnected. The wide-scale adoption of devices such as the smartphone is having a profound impact on our culture, communities, and economy. The use of social and digital media and associated means of communication enabled by mobile devices is changing the tone, content, and geographic scope of our conversations, modifying how information is generated and consumed, and changing the very nature of citizen engagement. \n",
      "Information technology-based platforms provisioned by private providers such as Facebook, Google, Uber, and Lyft maintain information about millions of citizens and enable services such as transportation that were mediated in the past solely by the public sector. Surveillance for purposes of public safety via large-scale deployment of sensors also raises fundamental questions about information privacy. From technology-enabled global delivery of work to displacement and replacement of categories of work, some studies estimate that up to 47 percent of U.S. employment might be at risk of computerization with an attendant rise in income inequality. These technology-induced changes will affect every policy domain. How should policy programs best prepare students to address societal challenges in this world that is being transformed by technology? We believe the answer lies in educating students to be “men and women of intelligent action.” \n",
      "A model of policy education\n",
      "We begin with a skills-based model of policy education. These four essential skills address the general problems policy practitioners frequently face:\n",
      "\n",
      "Design skills to craft policy ideas \n",
      "Analytical skills to make smart ex ante decisions \n",
      "Interpersonal experience to manage policy implementation  \n",
      "Evaluative skills to assess outcomes ex post and correct course if necessary\n",
      "\n",
      "These skills make up the policy analysis toolkit required to be data driven practitioner of “intelligent action” in any policy domain. This toolkit needs to be supplemented by an understanding of how technology is transforming societal challenges, enabling new solutions, or disrupting existing regulatory regimes. This understanding is essential to policy formulation and implementation. \n",
      "Pillar 1: Design skills\n",
      "As with engineering, where design precedes analysis, this first pillar seeks to educate students in thinking creatively about problems in order to devise and develop policy ideas. Using ideas derived from design, divergent and convergent thinking principles are employed to generate, explore, and arrive at a candidate set of solutions. Using Uber as an example, an approach to identify and explore the key policy issues such as convenience, costs, driver working hours, and insurance would involve interviewing and observing both incumbent taxi drivers and Uber drivers. This in turn would lead to a set of alternatives that deserve further and careful consideration.  Using these skills, candidate designs and choices that are generated can be evaluated using the policy analytic toolkit. \n",
      "Pillar 2: Analytical skills\n",
      "At Carnegie Mellon, we are often cited in media and interrogated by peers on our approach to analytical and technology skills education. Curiosity about which skills are the “right” skills to teach policy practitioners are common, but we believe this is the wrong approach. We instead begin from the premise that policy or management decisions should be grounded in evidence.  We then determine the skills required to assemble the types of evidence that will likely be available to policy makers in the future.  In increasingly instrumented environments where citizens and infrastructure produce continuous streams of data, making sense of it all will require a somewhat different set of skills. We believe that a grounding in micro-economics, operations research, statistics, and program evaluation (aka causal inference) to be an essential core to policy programs. \n",
      "New coursework will teach students to work with multi-variable data and machine learning with an emphasis on prediction. This material ought to be part of the required coursework in statistics given the importance of prediction in many policy implementation settings. Along the same lines, the ability to work with unstructured data (especially text) and data visualization will become increasingly relevant to all students, not just those students who want to specialize in data analytics. Finally, knowledge of data manipulation and analysis languages such as Python and R for analytic work will be important because data often has to be massaged and cleansed prior to analysis. An important task for programs will be to determine the competencies expected of graduates. \n",
      "Pillar 3: Interpersonal experiences\n",
      "The third pillar of the skills-based model is interpersonal experience, where the practiced habits of good communication and steady negotiation developed with a sound understanding of organizations, their design and their behaviors. We label these purposely as experiences rather than skills because we believe they are best practiced either in the real-world or in simulated real-world settings. It is also in this pillar where practitioners learn the knowledge necessary to become credible experts in their domain. We believe that in addition to core coursework in the area, a supplementary curriculum which provides students with opportunities to gain these experiences is an essential component of our educational model.\n",
      "Pillar 4: Evaluative skills\n",
      "\n",
      "\n",
      "Related Books\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Government Policy toward Open Source Software\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tEdited by Robert W. Hahn \n",
      "2002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Broadband\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tEdited by Robert W. Crandall and James H. Alleman \n",
      "2003\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "The Need for Speed\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tBy Robert E. Litan and Hal J. Singer \n",
      "2013\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The ability to carefully diagnose the effectiveness of policy or management interventions is the fourth pillar of our model. It is insufficient to create and execute policy without measurement, and this is where both careful thought to the fundamental issues of measurement and evaluation become important. The ability to make objective judgments on the benefits, liabilities, and unintended consequences of prior policies is the goal of this set of skills. Here, sound statistical and econometric training with an understanding of the principles of causal inference is essential. In addition, program evaluation skills such as cost-benefit and financial analysis help practitioners round out their evaluation skills by considering both non-monetary and economic impacts.\n",
      "What should be retired?\n",
      "A skills-based approach might replace certain aspects of existing policy training.  This depends on a number of factors specific to each institution, but three generally applicable observations are clear. First, real-world experiences are a powerful way to encode domain learning as well as project management skills. Through project-based work, students can learn about institutional contexts in specific policy domains and political processes such as budgeting. Second, team-based projects allow students to learn and apply principles of management and organizational behavior. At Carnegie Mellon, we refer to these as “systems synthesis” projects, since they require students to adopt a systemic point of view and to synthesize a number of skills in their policy analysis toolkit. Third, interpersonal skills training can be practiced through activities such as weekend negotiation exercises, hackathons, and speaker series. These activities can be highly intentional and fashioned to reinforce skills rather than as a recess from the “real work” of classroom training. Since students complete graduate programs in such a short time, counseling them to focus on outcomes from day one will allow them to choose a reinforcing set of coursework and real-world experiences. \n",
      "In summary, we argue for a model of policy education that views practitioners as future problem solvers. Good policy education must consider the ways in which problems will present themselves, and the ways in which answers will obscure themselves. Rigorous training grounded in the analysis of available evidence and buoyed by real-world interpersonal experiences is a sound approach to relevant, durable policy training.\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "R\n",
      "\n",
      "\n",
      "\n",
      "Ramayya Krishnan\n",
      "\n",
      "\t\t\t\t\tRamayya Krishnan is the dean of H. John Heinz III College of Information Systems and Public Policy at Carnegie Mellon University where he is the W.W. Cooper and Ruth F. Cooper Professor of Management Science and Information Systems.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "J\n",
      "\n",
      "\n",
      "\n",
      "Jon Nehlsen\n",
      "\n",
      "\t\t\t\t\tJon Nehlsen is senior director of external relations at H. John Heinz III College of Information Systems and Public Policy at Carnegie Mellon University.\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Read other essays in the Ideas to Retire blog series here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this works\n",
    "crawler.parse(\n",
    "    websites[2],\n",
    "    'https://www.brookings.edu/blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title and body not found\n"
     ]
    }
   ],
   "source": [
    "# this fails\n",
    "crawler.parse(\n",
    "    websites[3], \n",
    "    'https://www.nytimes.com/2018/01/28/business/energy-environment/oil-boom.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling through sites with search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"Common base class for all articles/pages\"\"\"\n",
    "    def __init__(self, topic, url, title, body):\n",
    "        self.topic = topic\n",
    "        self.url   = url\n",
    "        self.title = title\n",
    "        self.body  = body\n",
    "\n",
    "    def print(self):\n",
    "        \"\"\"\n",
    "        Flexible printing function controls output\n",
    "        \"\"\"\n",
    "        print('New article found for topic: {}'.format(self.topic))\n",
    "        print('URL: {}'.format(self.url))\n",
    "        print('TITLE: {}'.format(self.title))\n",
    "        print('WS turned off printing body for testing\\n')  # WS\n",
    "        # print('BODY:\\n{}'.format(self.body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"Contains information about website structure\"\"\"\n",
    "    def __init__(self, name, url, searchUrl, resultListing, resultUrl, absoluteUrl, titleTag, bodyTag):\n",
    "        self.name          = name\n",
    "        self.url           = url\n",
    "        self.searchUrl     = searchUrl\n",
    "        self.resultListing = resultListing\n",
    "        self.resultUrl     = resultUrl\n",
    "        self.absoluteUrl   = absoluteUrl\n",
    "        self.titleTag      = titleTag\n",
    "        self.bodyTag       = bodyTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "\n",
    "    def getPage(self, url):\n",
    "        try:\n",
    "            req = rq.get(url)\n",
    "        except rq.exceptions.RequestException:\n",
    "            return None\n",
    "        return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "    def safeGet(self, pageObj, selector):\n",
    "        childObj = pageObj.select(selector)\n",
    "        if childObj is not None and len(childObj) > 0:\n",
    "            return childObj[0].get_text()\n",
    "        return ''\n",
    "\n",
    "    def search(self, topic, site):\n",
    "        \"\"\"\n",
    "        Searches a given website for a given topic and records all pages found\n",
    "        \"\"\"\n",
    "        bs = self.getPage(site.searchUrl + topic)\n",
    "        searchResults = bs.select(site.resultListing)\n",
    "        for result in searchResults:\n",
    "            try:  # WS\n",
    "                url = result.select(site.resultUrl)[0].attrs['href']\n",
    "            except:\n",
    "                print('something wrong with finding URL')  # WS\n",
    "                return\n",
    "            # Check to see whether it's a relative or an absolute URL\n",
    "            if(site.absoluteUrl):\n",
    "                bs = self.getPage(url)\n",
    "            else:\n",
    "                bs = self.getPage(site.url + url)\n",
    "            if bs is None:\n",
    "                print('Something was wrong with that page or URL. Skipping!')\n",
    "                return\n",
    "            title = self.safeGet(bs, site.titleTag)\n",
    "            body  = self.safeGet(bs, site.bodyTag)\n",
    "            if title != '' and body != '':\n",
    "                content = Content(topic, url, title, body)  #  WS fixed order\n",
    "                content.print()\n",
    "            else:\n",
    "                print('title and body not found')  # WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler()\n",
    "\n",
    "siteData = [\n",
    "    ['O\\'Reilly Media', 'http://oreilly.com', 'https://ssearch.oreilly.com/?q=',\n",
    "        'article.product-result', 'p.title a', True, 'h1', 'section#product-description'],\n",
    "    ['Reuters', 'http://reuters.com', 'http://www.reuters.com/search/news?blob=', 'div.search-result-content',\n",
    "        'h3.search-result-title a', False, 'h1', 'div.StandardArticleBody_body_1gnLA'],\n",
    "    ['Brookings', 'http://www.brookings.edu', 'https://www.brookings.edu/search/?s=',\n",
    "        'div.list-content article', 'h4.title a', True, 'h1', 'div.post-body']\n",
    "]\n",
    "sites = []\n",
    "for row in siteData:\n",
    "    #sites.append(Website(row[0], row[1], row[2],\n",
    "    #                     row[3], row[4], row[5], row[6], row[7]))\n",
    "    sites.append(Website(*row)) # WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING INFO ABOUT: python\n",
      "checking site O'Reilly Media.\n",
      "checking site Reuters.\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "checking site Brookings.\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/blog/up-front/2022/03/17/housing-finance-reform-the-path-forward-gets-rolling/\n",
      "TITLE: Housing finance reform: The path forward gets rolling\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/research/how-open-source-software-shapes-ai-policy/\n",
      "TITLE: How open-source software shapes AI policy\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/research/preventing-pandemics-through-biodiversity-conservation-and-smart-wildlife-trade-regulation/\n",
      "TITLE: Preventing pandemics through biodiversity conservation and smart wildlife trade regulation\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/blog/techtank/2017/11/16/leveraging-the-disruptive-power-of-artificial-intelligence-for-fairer-opportunities/\n",
      "TITLE: Leveraging the disruptive power of artificial intelligence for fairer opportunities\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/blog/up-front/2015/12/21/the-hutchins-center-explains-budgeting-for-aging-america/\n",
      "TITLE: The Hutchins Center Explains: Budgeting for aging America\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/research/an-atlanta-organizations-mission-to-bring-racial-equity-to-the-tech-ecosystem/\n",
      "TITLE: An Atlanta organization’s mission to bring racial equity to the tech ecosystem\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/blog/the-avenue/2014/08/06/the-silicon-valley-wage-premium/\n",
      "TITLE: The Silicon Valley Wage Premium\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/\n",
      "TITLE: Idea to Retire: Old methods of policy education\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/opinions/skills-success-and-why-your-choice-of-college-matters/\n",
      "TITLE: Skills, success, and why your choice of college matters\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/research/institutionalizing-data-analysis-in-german-federal-governance/\n",
      "TITLE: Institutionalizing Data Analysis in German Federal Governance\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/research/making-waves-in-india-media-and-the-covid-19-pandemic/\n",
      "TITLE: Making waves in India: Media and the COVID-19 pandemic\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/essay/building-skills-for-life-how-to-expand-and-improve-computer-science-education-around-the-world/\n",
      "TITLE: \n",
      "\t\t\t\tBUILDING SKILLS FOR LIFE\t\t\t\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/opinions/inside-the-pentagons-secret-afghan-spy-machine/\n",
      "TITLE: Inside the Pentagon’s Secret Afghan Spy Machine\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/articles/the-new-urban-demographics-race-space-boomer-aging/\n",
      "TITLE: The New Urban Demographics: Race Space & Boomer Aging\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: python\n",
      "URL: https://www.brookings.edu/opinions/think-bigger-on-north-korea/\n",
      "TITLE: Think Bigger on North Korea\n",
      "WS turned off printing body for testing\n",
      "\n",
      "GETTING INFO ABOUT: data science\n",
      "checking site O'Reilly Media.\n",
      "checking site Reuters.\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "title and body not found\n",
      "checking site Brookings.\n",
      "New article found for topic: data science\n",
      "URL: https://www.brookings.edu/blog/how-we-rise/2021/10/29/reckoning-with-science-medicine-and-scapegoating/\n",
      "TITLE: Reckoning with science, medicine, and scapegoating\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: data science\n",
      "URL: https://www.brookings.edu/research/the-potential-of-the-chips-and-science-act-for-rural-america/\n",
      "TITLE: The potential of the CHIPS and Science Act for rural America\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: data science\n",
      "URL: https://www.brookings.edu/research/institutionalizing-data-analysis-in-german-federal-governance/\n",
      "TITLE: Institutionalizing Data Analysis in German Federal Governance\n",
      "WS turned off printing body for testing\n",
      "\n",
      "title and body not found\n",
      "New article found for topic: data science\n",
      "URL: https://www.brookings.edu/news-releases/ben-bernanke-distinguished-senior-fellow-in-residence-receives-nobel-prize-in-economic-sciences/\n",
      "TITLE: Ben Bernanke, distinguished senior fellow in residence, receives Nobel Prize in economic sciences\n",
      "WS turned off printing body for testing\n",
      "\n",
      "New article found for topic: data science\n",
      "URL: https://www.brookings.edu/blog/africa-in-focus/2022/01/26/investment-in-science-and-technology-is-key-to-an-african-economic-boom/\n",
      "TITLE: Investment in science and technology is key to an African economic boom\n",
      "WS turned off printing body for testing\n",
      "\n",
      "something wrong with finding URL\n"
     ]
    }
   ],
   "source": [
    "topics = ['python', 'data science']\n",
    "for topic in topics:\n",
    "    print('GETTING INFO ABOUT: ' + topic)\n",
    "    for targetSite in sites:\n",
    "        print('checking site {}.'.format(targetSite.name)) # WS\n",
    "        crawler.search(topic, targetSite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Sites through Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "\n",
    "    def __init__(self, name, url, targetPattern, absoluteUrl, titleTag, bodyTag):\n",
    "        self.name          = name\n",
    "        self.url           = url\n",
    "        self.targetPattern = targetPattern\n",
    "        self.absoluteUrl   = absoluteUrl\n",
    "        self.titleTag      = titleTag\n",
    "        self.bodyTag       = bodyTag\n",
    "\n",
    "class Content:\n",
    "\n",
    "    def __init__(self, url, title, body):\n",
    "        self.url   = url\n",
    "        self.title = title\n",
    "        self.body  = body\n",
    "\n",
    "    def print(self):\n",
    "        print('URL: {}'.format(self.url))\n",
    "        print('TITLE: {}'.format(self.title))\n",
    "        print('WS turned off printing body for testing\\n')  # WS\n",
    "        #print('BODY:\\n{}'.format(self.body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def __init__(self, site):\n",
    "        self.site    = site\n",
    "        self.visited = []\n",
    "\n",
    "    def getPage(self, url):\n",
    "        try:\n",
    "            req = rq.get(url)\n",
    "        except rq.exceptions.RequestException:\n",
    "            return None\n",
    "        return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "    def safeGet(self, pageObj, selector):\n",
    "        selectedElems = pageObj.select(selector)\n",
    "        if selectedElems is not None and len(selectedElems) > 0:\n",
    "            return '\\n'.join([elem.get_text() for elem in selectedElems])\n",
    "        return ''\n",
    "\n",
    "    def parse(self, url):\n",
    "        bs = self.getPage(url)\n",
    "        if bs is not None:\n",
    "            title = self.safeGet(bs, self.site.titleTag)\n",
    "            body = self.safeGet(bs, self.site.bodyTag)\n",
    "            if title != '' and body != '':\n",
    "                content = Content(url, title, body)\n",
    "                content.print()\n",
    "\n",
    "    def crawl(self):\n",
    "        \"\"\"\n",
    "        Get pages from website home page\n",
    "        \"\"\"\n",
    "        bs = self.getPage(self.site.url)\n",
    "        targetPages = bs.findAll('a', href=re.compile(self.site.targetPattern))\n",
    "        for targetPage in targetPages:\n",
    "            targetPage = targetPage.attrs['href']\n",
    "            if targetPage not in self.visited:\n",
    "                self.visited.append(targetPage)\n",
    "                if not self.site.absoluteUrl:\n",
    "                    targetPage = '{}{}'.format(self.site.url, targetPage)\n",
    "                self.parse(targetPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters = Website('Reuters', 'https://www.reuters.com', '^(/article/)',\n",
    "                  False, 'h1', 'div.StandardArticleBody_body_1gnLA')\n",
    "crawler = Crawler(reuters)\n",
    "crawler.crawl()  # this produces nothing: try Brookings, or study a reuters page to fix\n",
    "# stopped here 10/27/22: pick up from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling multiple page types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"Common base class for all articles/pages\"\"\"\n",
    "\n",
    "    def __init__(self, name, url, titleTag, bodyTag):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.titleTag = titleTag\n",
    "        self.bodyTag = bodyTag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(Website):\n",
    "    \"\"\"Contains information for scraping a product page\"\"\"\n",
    "\n",
    "    def __init__(self, name, url, titleTag, productNumber, price):\n",
    "        Website.__init__(self, name, url, TitleTag)\n",
    "        self.productNumberTag = productNumberTag\n",
    "        self.priceTag = priceTag\n",
    "\n",
    "class Article(Website):\n",
    "    \"\"\"Contains information for scraping an article page\"\"\"\n",
    "\n",
    "    def __init__(self, name, url, titleTag, bodyTag, dateTag):\n",
    "        Website.__init__(self, name, url, titleTag)\n",
    "        self.bodyTag = bodyTag\n",
    "        self.dateTag = dateTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parsePage(url):\n",
    "    \n",
    "    if '/ideas/' in url:\n",
    "        \n",
    "\n",
    "oreilly = Website('O\\'Reilly', 'https://oreilly.com', 'h1' '')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
